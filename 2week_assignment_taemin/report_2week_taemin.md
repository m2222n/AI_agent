# 2주차 과제 보고서 – AI 에이전트 핵심기능 프로토타입 개발  
작성자: 정태민  

---

## 1. 과제 개요

### 1.1. 과제 주제 요약
- **주제:** AI 에이전트 핵심기능 프로토타입 개발  
- **목표:**  
  1) 프로젝트 목표에 맞는 시스템 아키텍처를 설계하고,  
  2) OpenAI API 등 LLM을 연동하여,  
  3) 코드 기반 프로토타입(Tech-GPT 데모)을 구현하는 것이다.  

이번 2주차에서는 최종 서비스의 축소 버전으로, 내부 기술 문서를 기반으로 질의응답을 수행하는  
**“Tech-GPT 기술문의 에이전트”** 프로토타입을 설계·구현하였다.

---

## 2. 서비스 개요

### 2.1. 서비스 컨셉

- 이름: **Tech-GPT – 기술문의 AI 에이전트 (프로토타입)**  
- 대상 사용자: 사내 개발자 및 기획자 등 기술 문서에 자주 접근하는 내부 직원  
- 핵심 기능:
  - 자연어로 질문을 입력하면,
  - 사내 기술 문서(예시 데이터)를 기반으로 관련 정보를 찾아
  - 요약된 답변과 함께 참고 문서 목록을 제시

### 2.2. 프로토타입 범위

- 실제 사내 데이터 대신, 코드 내의 `DOCUMENTS` 리스트로 정의된 3개의 예시 문서를 사용
- 벡터 DB, 임베딩 검색 대신 **키워드 기반 간단 매칭 로직**으로 구현
- UI는 Streamlit 기반의 단일 페이지 웹 애플리케이션으로 구성

---

## 3. 시스템 아키텍처 설계

### 3.1. 전체 아키텍처 개요

본 프로토타입은 아래와 같은 레이어로 구성된다.

1. **사용자 인터페이스(UI)** – Streamlit 웹 앱  
2. **백엔드/오케스트레이션 레이어** – 질문 수신, 컨텍스트 구성, LLM 호출  
3. **문서 관리/검색 레이어** – 예시 문서 리스트 및 간단한 키워드 매칭  
4. **LLM 응답 생성 레이어** – OpenAI Chat Completions API를 통한 답변 생성  
5. **로깅/모니터링 레이어** – 질문·응답 로그 파일 저장

### 3.2. 논리 아키텍처 (텍스트 다이어그램)

```text
[사용자 (웹 브라우저)]
         |
         v
[Streamlit UI]
  - 질문 입력
  - 응답/참고문서 출력
         |
         v
[오케스트레이션 레이어]
  - build_context(question)
  - call_llm(context, question)
         |
         v
[문서 레이어 (예시 DOCUMENTS 리스트)]
  - 간단 키워드 매칭으로 관련 문서 선택
         |
         v
[LLM (OpenAI GPT-4.1 mini)]
  - RAG 스타일 프롬프트 기반 답변 생성
         |
         v
[로깅 레이어]
  - techgpt_log.txt 에 Q/A 기록
```

### 3.3. 컴포넌트별 역할

1. **Streamlit UI**
   - 사용자가 자연어로 질문을 입력
   - “질문하기” 버튼 클릭 시 백엔드 로직 실행
   - 결과로 생성된 답변과 참고 문서 목록을 화면에 표시

2. **오케스트레이션 레이어**
   - `build_context(question)`:
     - 질문 내용에서 간단한 키워드를 추출하여 관련 문서를 선택
     - 선택된 문서들을 하나의 큰 텍스트 컨텍스트로 합쳐 반환
   - `call_llm(context, question)`:
     - 시스템 프롬프트 + 사용자 프롬프트 템플릿을 구성
     - OpenAI API(Chat Completions)를 호출해 답변을 생성

3. **문서 레이어**
   - `DOCUMENTS` 리스트에 ID, 제목, 내용이 정의된 예시 문서 3개를 보관
   - 추후 3주차에서 벡터 DB(Chroma, FAISS 등)로 교체하거나 확장 가능

4. **LLM 레이어(OpenAI API)**
   - 모델: `gpt-4.1-mini` (경량 + 응답 속도/비용 고려)
   - 역할: 컨텍스트와 질문을 입력받아, RAG 스타일로 문서 기반 답변 생성

5. **로깅 레이어**
   - `techgpt_log.txt` 파일에 타임스탬프, 질문, 답변을 저장
   - 추후 품질 분석·프롬프트 튜닝·파인튜닝 데이터로 활용 가능

---

## 4. LLM 연동 및 프롬프트 엔지니어링

### 4.1. LLM 선택

- **모델:** OpenAI `gpt-4.1-mini`  
- **선택 이유:**
  - 한국어와 기술 문서 요약에 충분한 성능
  - 비용과 속도가 균형 잡혀 있어 반복 테스트에 적합
  - 추후 상위 모델(`gpt-4.1`, `o3` 등)로 교체 시 코드 변경이 최소화됨

### 4.2. 프롬프트 설계 원칙

- R-M-G-C / R.O.L.E 구조 활용:
  - **Role:** 사내 기술 문서를 잘 아는 시니어 엔지니어
  - **Message(Context):** `build_context()`에서 구성한 문서 컨텍스트
  - **Goal:** 문서에 기반한 사실 중심의 답변
  - **Constraint / Output / Length / Expectation:**
    - 한국어로 3~5문단 이내 요약
    - 문서에 없는 내용은 추측하지 말 것
    - 마지막에 “📎 참고 문서” 섹션으로 문서 ID를 정리할 것

### 4.3. 실제 프롬프트 템플릿

시스템 프롬프트:

> 너는 사내 기술 문서를 가장 잘 이해하는 시니어 엔지니어야.  
> 항상 사실 기반으로만 대답하고, 문서에 없는 내용은 추측하지 말고  
> '해당 문서 기준으로는 답변하기 어렵습니다'라고 답해.

사용자 프롬프트:

```text
[컨텍스트(문서 내용)]
{context}

[사용자 질문]
{question}

[출력 조건]
- 한국어로 답변해.
- 3~5문단 이내로, 중요한 내용을 위주로 설명해.
- 마지막에 "📎 참고 문서" 섹션을 만들어, 사용한 문서 ID를 bullet으로 정리해줘.
```

---

## 5. 프로토타입 구현

### 5.1. 사용 기술 스택

- 언어: Python 3.x  
- UI 프레임워크: Streamlit  
- LLM: OpenAI Chat Completions API (`gpt-4.1-mini`)  
- 기타:
  - 간단한 파일 기반 로깅 (`techgpt_log.txt`)

### 5.2. 주요 파일 구성

- `app.py` : Streamlit 기반 메인 애플리케이션
  - UI 렌더링
  - `build_context()`, `call_llm()`, `log_interaction()` 호출
- `techgpt_log.txt` : 실행 후 생성되는 로그 파일 (처음에는 없음)

### 5.3. 실행 방법

1. **필수 패키지 설치**

```bash
pip install streamlit openai
```

2. **OpenAI API 키 환경변수 설정**

- macOS / Linux

```bash
export OPENAI_API_KEY="sk-xxxxxxxx"
```

- Windows (PowerShell)

```powershell
setx OPENAI_API_KEY "sk-xxxxxxxx"
```

3. **앱 실행**

```bash
streamlit run app.py
```

4. **웹 브라우저에서 접속**

- 기본적으로 `http://localhost:8501` 에서 접속 가능  
- 질문 입력 후 **질문하기** 버튼을 클릭하면 LLM이 문서를 참고해 답변 생성

---

## 6. 한계점 및 향후 고도화(3주차 연계)

### 6.1. 현 시점 한계

- 문서 검색이 키워드 기반 `if` 문으로 구현되어 정확도가 제한적
- 실제 사내 DB, 문서 관리 시스템과 연동되지 않은 예시 데이터만 사용
- 로깅은 텍스트 파일 기반으로만 제공되고, 대시보드/모니터링은 미구현

### 6.2. 3주차 이후 확장 계획

1. **벡터 DB 및 임베딩 기반 검색 도입**
   - OpenAI Embeddings + Chroma/FAISS 를 활용하여 문서 검색 정확도 향상
   - 다양한 포맷(PDF, HWP, PPT 등)을 전처리 후 인덱싱

2. **클라우드 환경 배포**
   - GCP Cloud Run, AWS App Runner 등을 활용하여 컨테이너 기반 배포
   - 동시접속자, 응답 속도, 비용, 보안 정책을 고려한 운영 환경 설계

3. **모니터링/로깅 강화**
   - 로그를 DB나 로그 수집 시스템(예: Cloud Logging, CloudWatch)에 저장
   - 실패 요청, 응답 지연, 에러율 등을 대시보드로 시각화

4. **프롬프트/워크플로우 튜닝**
   - 사용자 피드백(좋아요/싫어요)을 수집하고,
   - 이를 반영한 프롬프트 개선 및 모델 파인튜닝 데이터셋 구축

---

## 7. 결론

2주차 과제에서는 Tech-GPT 기술문의 에이전트의 **핵심기능 프로토타입**을 설계·구현하였다.

- 시스템 아키텍처 측면에서는 UI–오케스트레이션–문서–LLM–로깅 레이어 구조를 정의하였고,
- LLM 연동 측면에서는 OpenAI Chat Completions API와 프롬프트 엔지니어링을 통해
  **문서 기반 RAG 스타일 질의응답 흐름**을 설계하였다.
- 구현 측면에서는 Streamlit 앱과 간단한 문서 매칭·로깅을 통해 실제 동작하는 데모를 완성하였다.

이 프로토타입은 3주차 이후,  
벡터 DB 연동 / 클라우드 배포 / 모니터링·로깅 강화 / 프롬프트 튜닝 등의 방향으로 자연스럽게 확장 가능하며,  
실제 실무 환경에서 사용할 수 있는 AI 에이전트 서비스의 기반이 되는 단계라고 할 수 있다.
