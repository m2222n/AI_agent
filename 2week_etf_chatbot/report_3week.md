# 3주차 과제 결과 보고서

## ETF 질의응답 챗봇 - MVP (Minimum Viable Product)

**작성일**: 2024-12-05
**프로젝트**: LLM 기반 ETF 질의응답 챗봇
**배포 URL**: Streamlit Cloud (https://github.com/m2222n/AI_agent)

---

## 1. 과제 목표

3주차 과제의 핵심 목표는 2주차에 개발한 프로토타입을 **실사용 가능한 MVP로 고도화**하는 것입니다.

### 주요 과제 항목
1. 프롬프트 튜닝 및 사용자 시나리오별 테스트
2. 다양한 입력값에 대한 모델 반응 테스트
3. 사용자 경험(UX)을 고려한 프롬프트 재설계
4. 에이전트 반응속도 및 정확도 개선
5. AI 서비스 최적화 및 통합
6. 모니터링 및 로깅을 통한 문제 탐지 및 대응 체계 구축

---

## 2. 구현 내용

### 2.1 프롬프트 엔지니어링 적용

멘토 제공 "프롬프트 엔지니어링 가이드"를 기반으로 다음 기법들을 적용했습니다:

#### 적용 기법

| 기법 | 적용 내용 |
|------|----------|
| **역할 지정** | "10년 경력의 ETF 투자 전문 어드바이저" 역할 부여 |
| **형식 지정** | #역할, #제약조건, #출력형식 구조화 |
| **Chain of Thought** | 비교/추천 질문에 "차근차근 단계별로" 추론 유도 |
| **Few-shot** | 추천 질문에 질의응답 예시 제공 |

#### 질문 유형별 프롬프트 최적화

```python
질문 유형:
- simple: 단일 ETF 정보 질문 → 구조화된 정보 제공
- compare: 비교 질문 → 표 형식 비교 + CoT 적용
- recommend: 추천 질문 → Few-shot + 단계별 추론
- risk: 위험 질문 → 균형잡힌 위험 설명
- general: 일반 질문 → 쉬운 개념 설명
```

### 2.2 질문 유형 자동 분류

사용자 질문을 자동으로 분류하여 최적화된 프롬프트를 적용합니다:

```python
def classify_question_type(question: str) -> str:
    # 키워드 기반 분류 로직
    # 비교 > 위험 > 단순정보 > 추천 > 일반 순서로 판별
```

### 2.3 응답 시간 측정 및 모니터링

모든 질의응답에 대해 상세 성능 메트릭을 측정하고 로깅합니다:

- **검색 시간**: 벡터 DB 유사도 검색 소요 시간
- **LLM 시간**: GPT-4o API 호출 소요 시간
- **전체 시간**: 총 응답 시간

#### 로그 형식 (chat_log.jsonl)
```json
{
  "timestamp": "2024-12-05T01:00:00",
  "question": "KODEX 200 ETF 알려줘",
  "question_type": "simple",
  "answer": "...",
  "sources": ["ETF-001"],
  "performance": {
    "search_time_ms": 150.5,
    "llm_time_ms": 5200.3,
    "total_time_ms": 5350.8
  }
}
```

### 2.4 성능 모니터링 대시보드

사이드바에 실시간 성능 통계를 표시합니다:
- 총 질의 수
- 평균 응답 시간
- 평균 검색 시간
- 질문 유형 분포

### 2.5 UX 개선

- 질문 유형 표시 (사용자에게 AI가 질문을 어떻게 이해했는지 표시)
- 응답 시간 표시 (투명성 제공)
- 스트리밍 응답 (실시간 답변 생성으로 체감 속도 향상)

---

## 3. 시나리오 테스트 결과

### 3.1 테스트 개요

| 항목 | 내용 |
|------|------|
| 총 테스트 수 | 17건 |
| 테스트 카테고리 | 5개 (simple, compare, recommend, risk, edge_case) |
| 테스트 도구 | test_scenarios.py (자동화 스크립트) |

### 3.2 테스트 결과 요약

| 지표 | 결과 |
|------|------|
| **성공률** | 100% (17/17) |
| **질문 유형 분류 정확도** | 88.2% (15/17) |
| **평균 응답 시간** | 6,428ms |

### 3.3 카테고리별 상세 결과

| 카테고리 | 테스트 수 | 평균 응답 시간 | 비고 |
|----------|----------|----------------|------|
| simple (단순 정보) | 3 | 4,882ms | 가장 빠른 응답 |
| compare (비교 분석) | 3 | 10,242ms | 복잡한 분석으로 시간 소요 |
| recommend (추천) | 4 | 6,291ms | 적절한 응답 시간 |
| risk (위험 분석) | 3 | 7,802ms | 상세 설명으로 시간 소요 |
| edge_case (예외) | 4 | 3,831ms | 짧은 응답으로 빠름 |

### 3.4 테스트 시나리오 상세

#### Simple (단순 정보) 질문
```
Q: "KODEX 200 ETF에 대해 알려줘"
→ 상품 개요, 핵심 정보, 투자 포인트 구조화 출력

Q: "TIGER 미국S&P500의 수수료는 얼마야?"
→ 0.07% 정확히 답변, 출처 표시
```

#### Compare (비교) 질문
```
Q: "KODEX 200과 TIGER 미국S&P500 비교해줘"
→ 표 형식 비교, 항목별 장단점 분석

Q: "2차전지 ETF와 전기차 ETF 중에 뭐가 더 위험해?"
→ 위험등급 비교, 투자자 유형별 추천
```

#### Recommend (추천) 질문
```
Q: "배당 수익률 높은 ETF 추천해줘"
→ KODEX 고배당 추천, 배당률 4-5% 설명

Q: "안정적인 투자를 원하는데 어떤 ETF가 좋을까?"
→ KODEX 단기채권 추천, 위험등급 5등급 설명
```

#### Risk (위험) 질문
```
Q: "인버스 ETF 투자할 때 주의사항이 뭐야?"
→ 복리 효과, 장기 보유 위험, 단기 헤지 목적 권장
```

#### Edge Case (예외) 질문
```
Q: "비트코인 ETF 있어?"
→ "보유한 데이터에 없습니다" 적절히 안내

Q: "삼성전자 주가 알려줘"
→ ETF 범위 외 질문임을 안내
```

---

## 4. 개선 효과

### 4.1 2주차 대비 개선 사항

| 항목 | 2주차 | 3주차 | 개선 |
|------|-------|-------|------|
| 프롬프트 | 단순 역할 정의 | 5가지 기법 적용 | 응답 품질 향상 |
| 질문 분류 | 없음 | 5가지 유형 자동 분류 | 맞춤형 응답 |
| 성능 측정 | 없음 | 검색/LLM/전체 시간 측정 | 모니터링 가능 |
| 로깅 | 기본 로깅 | 상세 메트릭 포함 | 분석 가능 |
| UX | 기본 UI | 성능 지표/유형 표시 | 투명성 향상 |

### 4.2 응답 품질 개선

- **구조화된 출력**: 마크다운 형식으로 가독성 향상
- **출처 명시**: [ETF-XXX] 형식으로 신뢰성 확보
- **투자 유의사항**: 모든 답변에 위험 고지 포함
- **맞춤형 답변**: 질문 유형별 최적화된 응답 형식

---

## 5. 기술 스택

| 구분 | 기술 |
|------|------|
| LLM | OpenAI GPT-4o |
| Vector DB | FAISS (LangChain) |
| Framework | LangChain |
| UI | Streamlit |
| 배포 | Streamlit Cloud |

---

## 6. 파일 구조

```
2week_etf_chatbot/
├── app.py                 # 메인 애플리케이션 (3주차 고도화)
├── test_scenarios.py      # 시나리오 테스트 스크립트
├── test_report.json       # 테스트 결과 (JSON)
├── report_3week.md        # 3주차 보고서 (본 문서)
├── requirements.txt       # 의존성
├── data/
│   └── etf_data.json      # ETF 샘플 데이터 (8개)
└── logs/
    ├── chat_log.jsonl     # 질의응답 로그
    └── feedback_log.jsonl # 피드백 로그
```

---

## 7. 실행 방법

### 로컬 실행
```bash
cd /Users/m2222n/AI_agent
source .venv/bin/activate
cd 2week_etf_chatbot
export OPENAI_API_KEY="your-key"
streamlit run app.py
```

### 테스트 실행
```bash
python test_scenarios.py
```

---

## 8. 향후 개선 방향

1. **성능 최적화**
   - 응답 시간 5초 이내 목표
   - 캐싱 시스템 도입

2. **데이터 확장**
   - 실제 ETF API 연동
   - 실시간 시세 정보 추가

3. **모니터링 고도화**
   - Grafana 대시보드 연동
   - 알림 시스템 구축

4. **프롬프트 지속 개선**
   - A/B 테스트로 최적 프롬프트 탐색
   - 사용자 피드백 기반 튜닝

---

## 9. 결론

3주차 과제를 통해 2주차 프로토타입을 실사용 가능한 MVP 수준으로 고도화했습니다.

### 핵심 성과
- **프롬프트 엔지니어링 5가지 기법 적용**으로 응답 품질 향상
- **질문 유형 자동 분류**로 맞춤형 응답 제공
- **성능 모니터링 시스템** 구축으로 지속적 개선 가능
- **시나리오 테스트 100% 성공**으로 안정성 검증

본 프로젝트는 LLM 기반 금융 서비스의 실무 적용 가능성을 보여주며, 향후 데이터 확장과 성능 최적화를 통해 상용 서비스 수준으로 발전시킬 수 있습니다.

---

_작성: AI Agent 부트캠프 3주차_
