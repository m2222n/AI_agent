"""
ETF ì§ˆì˜ì‘ë‹µ ì±—ë´‡ - 3ì£¼ì°¨ MVP (Minimum Viable Product)

LLM ê¸°ë°˜ ETF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ
- RAG íŒŒì´í”„ë¼ì¸: LangChain + FAISS (Vector DB)
- LLM: OpenAI GPT-4o
- UI: Streamlit

[2ì£¼ì°¨] ë©˜í†  í”¼ë“œë°± ë°˜ì˜:
1. ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê¸°ë¡ (st.session_state)
2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì‹¤ì‹œê°„ ë‹µë³€ ìƒì„±)
3. API ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™” (RateLimitError, APIConnectionError ë“±)
4. ì¸ë¼ì¸ ì¶œì²˜ í‘œì‹œ ([ETF-001] í˜•ì‹)
5. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (ì¢‹ì•„ìš”/ì‹«ì–´ìš”)
6. Edge Case ì²˜ë¦¬ (ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ ëª…ì‹œì  ì•ˆë‚´)

[3ì£¼ì°¨] ê³ ë„í™” ì ìš©:
1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (ì—­í• ì§€ì •/í˜•ì‹ì§€ì •/CoT/Few-shot)
2. ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ë¥˜ ë° ìµœì í™” ì²˜ë¦¬
3. ì‘ë‹µ ì‹œê°„ ì¸¡ì • ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
4. ìƒì„¸ ë¡œê¹… ì‹œìŠ¤í…œ (ê²€ìƒ‰/LLM/ì „ì²´ ì‹œê°„)
5. UX ê°œì„  (ë¡œë”© ìƒíƒœ, ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ)
"""

import os
import json
import time
from datetime import datetime
from typing import List, Tuple

import streamlit as st
from openai import OpenAI, APIError, RateLimitError, APIConnectionError

# LangChain imports
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

# -------------------------------------------------------------------
# 0. í™˜ê²½ ì„¤ì •
# -------------------------------------------------------------------
def init_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    # Streamlit Cloud secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
    api_key = None

    # 1. Streamlit secretsì—ì„œ ë¨¼ì € í™•ì¸ (Cloud ë°°í¬ìš©)
    try:
        api_key = st.secrets["OPENAI_API_KEY"]
    except (KeyError, FileNotFoundError):
        pass

    # 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ í™•ì¸ (ë¡œì»¬ ê°œë°œìš©)
    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.info("Streamlit Cloud: Settings â†’ Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()
    return OpenAI(api_key=api_key)

# -------------------------------------------------------------------
# 1. ETF ë°ì´í„° ë¡œë“œ ë° ë²¡í„° DB ì´ˆê¸°í™”
# -------------------------------------------------------------------
@st.cache_resource
def load_etf_data() -> List[dict]:
    """ETF ë°ì´í„° ë¡œë“œ"""
    data_path = os.path.join(os.path.dirname(__file__), "data", "etf_data.json")
    with open(data_path, "r", encoding="utf-8") as f:
        return json.load(f)

@st.cache_resource
def init_vector_db():
    """FAISS ë²¡í„° DB ì´ˆê¸°í™”"""
    etf_data = load_etf_data()

    # ETF ë°ì´í„°ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
    documents = []
    for etf in etf_data:
        # ëª¨ë“  ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        content = f"""
ETF ID: {etf['id']}
ìƒí’ˆëª…: {etf['name']} ({etf['ticker']})
ì¹´í…Œê³ ë¦¬: {etf['category']}
ì¶”ì¢…ì§€ìˆ˜: {etf['index']}
ìš´ìš©ì‚¬: {etf['asset_manager']}
ì´ë³´ìˆ˜: {etf['total_expense_ratio']}
ìˆœìì‚°ê°€ì¹˜(NAV): {etf['nav']}
ìˆœìì‚°ì´ì•¡(AUM): {etf['aum']}
ìƒì¥ì¼: {etf['listing_date']}
ì„¤ëª…: {etf['description']}
ìœ„í—˜ë“±ê¸‰: {etf['risk_level']}
íˆ¬ìì „ëµ: {etf['investment_strategy']}
ì£¼ìš” ë³´ìœ ì¢…ëª©: {', '.join(etf['top_holdings'])}
ë°°ë‹¹ì •ì±…: {etf['dividend_policy']}
ì¶”ì ì˜¤ì°¨: {etf['tracking_error']}
íˆ¬ìì ìœ ì˜ì‚¬í•­: {etf['investor_caution']}
"""
        doc = Document(
            page_content=content,
            metadata={"id": etf["id"], "name": etf["name"], "ticker": etf["ticker"]}
        )
        documents.append(doc)

    # OpenAI ì„ë² ë”©ìœ¼ë¡œ FAISS ë²¡í„° DB ìƒì„±
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(
        documents=documents,
        embedding=embeddings
    )

    return vectorstore

# -------------------------------------------------------------------
# 2. RAG ê²€ìƒ‰ í•¨ìˆ˜
# -------------------------------------------------------------------
def retrieve_relevant_docs(vectorstore, query: str, k: int = 3) -> Tuple[str, List[dict]]:
    """
    ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

    Returns:
        context: ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© (ë¬¸ìì—´)
        sources: ì¶œì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    results = vectorstore.similarity_search_with_score(query, k=k)

    # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ (threshold: 1.5 ì´í•˜ë§Œ ì‚¬ìš©)
    filtered_results = [(doc, score) for doc, score in results if score < 1.5]

    if not filtered_results:
        # Edge Case: ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        return None, []

    context_parts = []
    sources = []

    for doc, score in filtered_results:
        context_parts.append(f"[{doc.metadata['id']}] {doc.page_content}")
        sources.append({
            "id": doc.metadata["id"],
            "name": doc.metadata["name"],
            "ticker": doc.metadata["ticker"],
            "relevance_score": round(1 - score/2, 2)  # ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ë³€í™˜
        })

    context = "\n\n---\n\n".join(context_parts)
    return context, sources

# -------------------------------------------------------------------
# 3. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ (3ì£¼ì°¨ ì¶”ê°€)
# -------------------------------------------------------------------
def classify_question_type(question: str) -> str:
    """
    ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì—¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì ìš©

    ìœ í˜•:
    - simple: ë‹¨ì¼ ETF ì •ë³´ ì§ˆë¬¸ ("KODEX 200 ìˆ˜ìµë¥ ì€?")
    - compare: ë¹„êµ ì§ˆë¬¸ ("Aì™€ B ë¹„êµí•´ì¤˜")
    - recommend: ì¶”ì²œ ì§ˆë¬¸ ("ë°°ë‹¹ ë†’ì€ ETF ì¶”ì²œ")
    - risk: ìœ„í—˜/ì£¼ì˜ì‚¬í•­ ì§ˆë¬¸ ("ìœ„í—˜ë„", "ì£¼ì˜")
    - general: ì¼ë°˜ ETF ì§€ì‹ ì§ˆë¬¸

    [3ì£¼ì°¨ ê°œì„ ] ë¶„ë¥˜ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ìš°ì„ ìˆœìœ„ ì¡°ì •
    """
    question_lower = question.lower()

    # íŠ¹ì • ETF ì´ë¦„ì´ ì–¸ê¸‰ë˜ë©´ ìš°ì„  ì²´í¬
    etf_names = ["kodex", "tiger", "ì½”ë±ìŠ¤", "íƒ€ì´ê±°", "etf-"]
    has_specific_etf = any(name in question_lower for name in etf_names)

    # 1. ë¹„êµ ì§ˆë¬¸ íŒ¨í„´ (ìµœìš°ì„ )
    compare_keywords = ["ë¹„êµ", "ì°¨ì´", "vs", "ì¤‘ì—", "ì–´ë–¤ê²Œ", "ì–´ë–¤ ê²Œ", "ë‘˜ ì¤‘"]
    # "ì™€ ", "ê³¼ "ëŠ” ë¹„êµ ë§¥ë½ì—ì„œë§Œ ì‚¬ìš©
    compare_connectors = ["ì™€ ", "ê³¼ "]
    has_compare_connector = any(conn in question_lower for conn in compare_connectors)
    has_compare_keyword = any(kw in question_lower for kw in compare_keywords)

    if has_compare_keyword or (has_compare_connector and has_specific_etf):
        return "compare"

    # 2. ìœ„í—˜/ì£¼ì˜ ì§ˆë¬¸ íŒ¨í„´
    risk_keywords = ["ìœ„í—˜", "ë¦¬ìŠ¤í¬", "ì£¼ì˜", "ì†ì‹¤", "ì•ˆì „", "ë³€ë™ì„±"]
    if any(kw in question_lower for kw in risk_keywords):
        return "risk"

    # 3. íŠ¹ì • ETF ì •ë³´ ì§ˆë¬¸ (ë‹¨ìˆœ ì •ë³´ ìš”ì²­)
    # "ì•Œë ¤ì¤˜", "ë­ì•¼", "ì–¼ë§ˆ" ë“±ê³¼ í•¨ê»˜ íŠ¹ì • ETF ì–¸ê¸‰ ì‹œ simple
    info_keywords = ["ì•Œë ¤ì¤˜", "ë­ì•¼", "ë­ì˜ˆìš”", "ì–¼ë§ˆ", "ë¬´ì—‡", "ì„¤ëª…", "ì •ë³´", "ì— ëŒ€í•´"]
    if has_specific_etf and any(kw in question_lower for kw in info_keywords):
        return "simple"

    # 4. ì¶”ì²œ ì§ˆë¬¸ íŒ¨í„´ (ì¡°ê±´ë¶€ ì¶”ì²œ)
    recommend_keywords = ["ì¶”ì²œ", "ì¢‹ì€", "ê´œì°®ì€", "ì–´ë–¤ etf", "ë­ê°€ ì¢‹", "ê³¨ë¼", "ì„ íƒ"]
    if any(kw in question_lower for kw in recommend_keywords):
        return "recommend"

    # 5. íŠ¹ì • ETF ì´ë¦„ë§Œ ìˆìœ¼ë©´ simple
    if has_specific_etf:
        return "simple"

    return "general"

# -------------------------------------------------------------------
# 4. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‹œìŠ¤í…œ (3ì£¼ì°¨ í•µì‹¬)
# -------------------------------------------------------------------
def build_system_prompt(question_type: str) -> str:
    """
    ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±

    í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²• ì ìš©:
    - ì—­í•  ì§€ì • (Role)
    - í˜•ì‹ ì§€ì • (Format)
    - ì œì•½ì¡°ê±´ (Constraints)
    - Chain of Thought (CoT) - ë¹„êµ/ì¶”ì²œ ì§ˆë¬¸
    - Few-shot ì˜ˆì‹œ
    """

    # ê¸°ë³¸ ì—­í•  ì •ì˜ (ì—­í•  ì§€ì • ê¸°ë²•)
    base_role = """#ì—­í• 
ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ETF íˆ¬ì ì „ë¬¸ ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤.
ê¸ˆìœµíˆ¬ìí˜‘íšŒ ì¸ì¦ íˆ¬ììƒë‹´ì‚¬ ìê²©ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°,
ê°œì¸ íˆ¬ììì—ê²Œ ETF ìƒí’ˆ ì •ë³´ë¥¼ ì‰½ê³  ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤."""

    # ê³µí†µ ì œì•½ì¡°ê±´ (í˜•ì‹ ì§€ì • ê¸°ë²•)
    base_constraints = """
#ì œì•½ì¡°ê±´
- ì œê³µëœ ETF ë¬¸ì„œ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ëŠ” ë³´ìœ í•œ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì•ˆë‚´í•©ë‹ˆë‹¤
- ETF ì •ë³´ ì¸ìš© ì‹œ ë°˜ë“œì‹œ [ETF-XXX] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤
- íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹Œ ì •ë³´ ì œê³µì„ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰¬ìš´ ì„¤ëª…ì„ ë§ë¶™ì…ë‹ˆë‹¤"""

    # ì§ˆë¬¸ ìœ í˜•ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
    type_specific = {
        "simple": """
#ë‹µë³€ ë°©ì‹
ë‹¨ì¼ ETFì— ëŒ€í•œ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#ì¶œë ¥í˜•ì‹
1. **ìƒí’ˆ ê°œìš”**: ì´ë¦„, í‹°ì»¤, ìš´ìš©ì‚¬
2. **í•µì‹¬ ì •ë³´**: ìˆ˜ìˆ˜ë£Œ, ìœ„í—˜ë“±ê¸‰, ë°°ë‹¹ì •ì±…
3. **íˆ¬ì í¬ì¸íŠ¸**: ì£¼ìš” íŠ¹ì§• 2-3ê°œ
4. âš ï¸ **íˆ¬ì ìœ ì˜ì‚¬í•­**
5. ğŸ“ **ì°¸ê³  ETF**: [ETF-XXX]""",

        "compare": """
#ë‹µë³€ ë°©ì‹
ì°¨ê·¼ì°¨ê·¼ ë‹¨ê³„ë³„ë¡œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. (Chain of Thought)

ë¨¼ì €, ê° ETFì˜ í•µì‹¬ íŠ¹ì§•ì„ íŒŒì•…í•©ë‹ˆë‹¤.
ë‹¤ìŒìœ¼ë¡œ, ì£¼ìš” í•­ëª©ë³„ë¡œ ë¹„êµí•©ë‹ˆë‹¤.
ë§ˆì§€ë§‰ìœ¼ë¡œ, íˆ¬ìì ìƒí™©ë³„ ì í•©ì„±ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

#ì¶œë ¥í˜•ì‹
1. **ë¹„êµ ëŒ€ìƒ**: ê° ETF ê°„ë‹¨ ì†Œê°œ
2. **í•­ëª©ë³„ ë¹„êµí‘œ**:
   | í•­ëª© | ETF A | ETF B |
   |------|-------|-------|
   | ìˆ˜ìˆ˜ë£Œ | | |
   | ìœ„í—˜ë“±ê¸‰ | | |
   | ë°°ë‹¹ | | |
3. **ë¶„ì„ ìš”ì•½**: ê°ê°ì˜ ì¥ë‹¨ì 
4. **íˆ¬ìì ìœ í˜•ë³„ ì¶”ì²œ**
5. âš ï¸ **íˆ¬ì ìœ ì˜ì‚¬í•­**
6. ğŸ“ **ì°¸ê³  ETF**""",

        "recommend": """
#ë‹µë³€ ë°©ì‹
ë…¼ë¦¬ì ìœ¼ë¡œ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ í†µí•´ ì¶”ì²œí•©ë‹ˆë‹¤. (Chain of Thought)

ìš°ì„ , ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ íŒŒì•…í•©ë‹ˆë‹¤.
ê·¸ ë‹¤ìŒ, ì¡°ê±´ì— ë§ëŠ” ETFë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
ë§ˆì§€ë§‰ìœ¼ë¡œ, ì í•©í•œ ìˆœì„œëŒ€ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.

#Few-shot ì˜ˆì‹œ
Q: "ë°°ë‹¹ ìˆ˜ìµë¥  ë†’ì€ ETF ì¶”ì²œí•´ì¤˜"
A: ë°°ë‹¹ ìˆ˜ìµë¥ ì„ ì¤‘ì‹œí•˜ì‹œëŠ”êµ°ìš”. ë³´ìœ  ë°ì´í„° ì¤‘ ë°°ë‹¹ ê´€ë ¨ ETFë¥¼ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.

[ETF-006] KODEX ê³ ë°°ë‹¹ì€ ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 50ê°œ ì¢…ëª©ì— íˆ¬ìí•˜ë©°,
ì—° 4~5%ì˜ ë°°ë‹¹ìˆ˜ìµë¥ ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶„ê¸° ë°°ë‹¹ìœ¼ë¡œ ì •ê¸°ì ì¸
í˜„ê¸ˆíë¦„ì„ ì›í•˜ì‹œëŠ” ë¶„ê»˜ ì í•©í•©ë‹ˆë‹¤.

ë‹¤ë§Œ ê¸ˆìœµì£¼ ë¹„ì¤‘ì´ ë†’ì•„ ê¸ˆë¦¬ ë³€ë™ì— ë¯¼ê°í•œ ì  ì°¸ê³ í•´ì£¼ì„¸ìš”.

#ì¶œë ¥í˜•ì‹
1. **ìš”êµ¬ì‚¬í•­ íŒŒì•…**: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¡°ê±´
2. **ì¶”ì²œ ETF**: ì¡°ê±´ ë¶€í•© ìƒí’ˆ (ìš°ì„ ìˆœìœ„ ìˆœ)
3. **ì¶”ì²œ ì´ìœ **: ê° ìƒí’ˆë³„ ì¥ì 
4. **ëŒ€ì•ˆ**: ì°¨ì„ ì±… ETF
5. âš ï¸ **íˆ¬ì ìœ ì˜ì‚¬í•­**
6. ğŸ“ **ì°¸ê³  ETF**""",

        "risk": """
#ë‹µë³€ ë°©ì‹
íˆ¬ì ìœ„í—˜ì„ ì •í™•í•˜ê³  ê· í˜•ìˆê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

#ì¶œë ¥í˜•ì‹
1. **ìœ„í—˜ë“±ê¸‰ ì„¤ëª…**: 1~5ë“±ê¸‰ ì˜ë¯¸
2. **ì£¼ìš” ìœ„í—˜ ìš”ì†Œ**: í•´ë‹¹ ETFì˜ ë¦¬ìŠ¤í¬
3. **ìœ„í—˜ ê´€ë¦¬ ë°©ì•ˆ**: ë¶„ì‚°íˆ¬ì ë“± ì œì•ˆ
4. âš ï¸ **ë°˜ë“œì‹œ ì•Œì•„ì•¼ í•  ì‚¬í•­**
5. ğŸ“ **ì°¸ê³  ETF**""",

        "general": """
#ë‹µë³€ ë°©ì‹
ETF ì¼ë°˜ ì§€ì‹ì„ ì‰½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

#ì¶œë ¥í˜•ì‹
1. **í•µì‹¬ ê°œë…**: ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ ë‹µë³€
2. **ìƒì„¸ ì„¤ëª…**: ì¶”ê°€ ì •ë³´
3. **ê´€ë ¨ ETF ì˜ˆì‹œ**: í•´ë‹¹ë˜ëŠ” ê²½ìš°
4. ğŸ“ **ì°¸ê³  ETF** (í•´ë‹¹ ì‹œ)"""
    }

    return f"{base_role}\n{base_constraints}\n{type_specific.get(question_type, type_specific['general'])}"

# -------------------------------------------------------------------
# 5. LLM í˜¸ì¶œ í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›) - 3ì£¼ì°¨ ê°œì„ 
# -------------------------------------------------------------------
def call_llm_streaming(client: OpenAI, context: str, question: str, chat_history: list, question_type: str = "general"):
    """
    OpenAI API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ

    [2ì£¼ì°¨] ë©˜í†  í”¼ë“œë°± ë°˜ì˜:
    - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ UX ê°œì„ 
    - ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”
    - ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜ì˜

    [3ì£¼ì°¨] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì ìš©:
    - ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì í™” í”„ë¡¬í”„íŠ¸
    - ì—­í•  ì§€ì • / í˜•ì‹ ì§€ì • / CoT / Few-shot
    """
    # ì§ˆë¬¸ ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    system_prompt = build_system_prompt(question_type)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë©”ì‹œì§€ì— í¬í•¨
    messages = [{"role": "system", "content": system_prompt}]

    # ìµœê·¼ 5ê°œì˜ ëŒ€í™”ë§Œ í¬í•¨ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬)
    for msg in chat_history[-10:]:
        messages.append({"role": msg["role"], "content": msg["content"]})

    # í˜„ì¬ ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸
    if context:
        user_message = f"""[ê²€ìƒ‰ëœ ETF ë¬¸ì„œ]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜. ë‹µë³€ ì‹œ ì¶œì²˜ë¥¼ [ETF-XXX] í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•´."""
    else:
        user_message = f"""[ì‹œìŠ¤í…œ ì•Œë¦¼] ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ETF ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

ì¼ë°˜ì ì¸ ETF ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ë˜, "ì œê³µëœ ETF ë°ì´í„°ì—ì„œëŠ” ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"ë¼ê³  ë¨¼ì € ì•ˆë‚´í•´ì¤˜."""

    messages.append({"role": "user", "content": user_message})

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.3,  # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
            stream=True,
            timeout=60
        )
        return response

    except RateLimitError:
        st.error("âš ï¸ API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    except APIConnectionError:
        st.error("âš ï¸ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except APIError as e:
        st.error(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        st.error(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

# -------------------------------------------------------------------
# 6. ë¡œê¹… í•¨ìˆ˜ (3ì£¼ì°¨ ê°•í™”)
# -------------------------------------------------------------------
def log_interaction(
    question: str,
    answer: str,
    sources: list,
    question_type: str = "general",
    search_time: float = 0,
    llm_time: float = 0,
    total_time: float = 0,
    feedback: str = None
):
    """
    ì§ˆì˜ì‘ë‹µ ë¡œê·¸ ì €ì¥ (3ì£¼ì°¨: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ê°€)

    ê¸°ë¡ í•­ëª©:
    - ì§ˆë¬¸/ë‹µë³€ ë‚´ìš©
    - ì§ˆë¬¸ ìœ í˜• (simple/compare/recommend/risk/general)
    - ê²€ìƒ‰ ì‹œê°„, LLM ì‘ë‹µ ì‹œê°„, ì „ì²´ ì²˜ë¦¬ ì‹œê°„
    - ì‚¬ìš©ëœ ETF ì¶œì²˜
    - ì‚¬ìš©ì í”¼ë“œë°±
    """
    log_dir = os.path.join(os.path.dirname(__file__), "logs")
    os.makedirs(log_dir, exist_ok=True)

    log_file = os.path.join(log_dir, "chat_log.jsonl")

    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "question": question,
        "question_type": question_type,
        "answer": answer,
        "sources": [s["id"] for s in sources] if sources else [],
        "performance": {
            "search_time_ms": round(search_time * 1000, 2),
            "llm_time_ms": round(llm_time * 1000, 2),
            "total_time_ms": round(total_time * 1000, 2)
        },
        "feedback": feedback
    }

    with open(log_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

def log_feedback(question: str, answer: str, feedback: str):
    """ì‚¬ìš©ì í”¼ë“œë°± ë¡œê·¸"""
    log_dir = os.path.join(os.path.dirname(__file__), "logs")
    os.makedirs(log_dir, exist_ok=True)

    feedback_file = os.path.join(log_dir, "feedback_log.jsonl")

    entry = {
        "timestamp": datetime.now().isoformat(),
        "question": question,
        "answer": answer[:200] + "..." if len(answer) > 200 else answer,
        "feedback": feedback
    }

    with open(feedback_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

def get_performance_stats() -> dict:
    """
    ë¡œê·¸ì—ì„œ ì„±ëŠ¥ í†µê³„ ê³„ì‚° (3ì£¼ì°¨ ì¶”ê°€)
    """
    log_file = os.path.join(os.path.dirname(__file__), "logs", "chat_log.jsonl")

    if not os.path.exists(log_file):
        return None

    total_times = []
    search_times = []
    llm_times = []
    question_types = {}

    try:
        with open(log_file, "r", encoding="utf-8") as f:
            for line in f:
                entry = json.loads(line)
                if "performance" in entry:
                    perf = entry["performance"]
                    total_times.append(perf.get("total_time_ms", 0))
                    search_times.append(perf.get("search_time_ms", 0))
                    llm_times.append(perf.get("llm_time_ms", 0))

                q_type = entry.get("question_type", "unknown")
                question_types[q_type] = question_types.get(q_type, 0) + 1

        if not total_times:
            return None

        return {
            "total_queries": len(total_times),
            "avg_total_time_ms": round(sum(total_times) / len(total_times), 2),
            "avg_search_time_ms": round(sum(search_times) / len(search_times), 2),
            "avg_llm_time_ms": round(sum(llm_times) / len(llm_times), 2),
            "question_types": question_types
        }
    except Exception:
        return None

# -------------------------------------------------------------------
# 7. Streamlit UI (3ì£¼ì°¨ ê°œì„ )
# -------------------------------------------------------------------
def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ETF ì§ˆì˜ì‘ë‹µ ì±—ë´‡",
        page_icon="ğŸ“ˆ",
        layout="wide"
    )

    # í—¤ë”
    st.title("ğŸ“ˆ ETF ì§ˆì˜ì‘ë‹µ ì±—ë´‡")
    st.caption("LLM ê¸°ë°˜ ETF íˆ¬ì ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ | 3ì£¼ì°¨ MVP")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("â„¹ï¸ ì„œë¹„ìŠ¤ ì•ˆë‚´")
        st.markdown("""
        ì´ ì±—ë´‡ì€ **ETF íˆ¬ì ì •ë³´**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

        **ì£¼ìš” ê¸°ëŠ¥:**
        - ETF ìƒí’ˆ ì •ë³´ ê²€ìƒ‰
        - íˆ¬ì ì „ëµ ì„¤ëª…
        - ìœ„í—˜ë„/ìˆ˜ìˆ˜ë£Œ ë¹„êµ
        - ë°°ë‹¹ ì •ì±… ì•ˆë‚´

        **ì§€ì› ETF:**
        - êµ­ë‚´ ì£¼ì‹í˜• (KODEX 200 ë“±)
        - í•´ì™¸ ì£¼ì‹í˜• (S&P500, ë‚˜ìŠ¤ë‹¥100)
        - ì„¹í„°/í…Œë§ˆí˜• (2ì°¨ì „ì§€, ì „ê¸°ì°¨)
        - ì±„ê¶Œí˜• (ë‹¨ê¸°ì±„ê¶Œ)
        - ë°°ë‹¹í˜•, ì¸ë²„ìŠ¤í˜•
        """)

        st.divider()

        st.header("ğŸ“Š ETF ëª©ë¡")
        etf_data = load_etf_data()
        for etf in etf_data:
            with st.expander(f"{etf['name']} ({etf['ticker']})"):
                st.write(f"**ì¹´í…Œê³ ë¦¬:** {etf['category']}")
                st.write(f"**ìœ„í—˜ë“±ê¸‰:** {etf['risk_level']}")
                st.write(f"**ì´ë³´ìˆ˜:** {etf['total_expense_ratio']}")

        st.divider()

        st.warning("""
        âš ï¸ **íˆ¬ì ìœ ì˜ì‚¬í•­**

        ë³¸ ì„œë¹„ìŠ¤ëŠ” ì •ë³´ ì œê³µ ëª©ì ì´ë©°,
        íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤.
        íˆ¬ì ê²°ì •ì€ ë³¸ì¸ì˜ íŒë‹¨ê³¼
        ì±…ì„ í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.
        """)

        # 3ì£¼ì°¨ ì¶”ê°€: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
        st.divider()
        st.header("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        stats = get_performance_stats()
        if stats:
            st.metric("ì´ ì§ˆì˜ ìˆ˜", stats["total_queries"])
            col1, col2 = st.columns(2)
            with col1:
                st.metric("í‰ê·  ì‘ë‹µì‹œê°„", f"{stats['avg_total_time_ms']:.0f}ms")
            with col2:
                st.metric("í‰ê·  ê²€ìƒ‰ì‹œê°„", f"{stats['avg_search_time_ms']:.0f}ms")

            # ì§ˆë¬¸ ìœ í˜• ë¶„í¬
            if stats["question_types"]:
                st.markdown("**ì§ˆë¬¸ ìœ í˜• ë¶„í¬:**")
                for q_type, count in stats["question_types"].items():
                    pct = count / stats["total_queries"] * 100
                    st.progress(pct / 100, text=f"{q_type}: {count}ê±´ ({pct:.0f}%)")
        else:
            st.info("ì•„ì§ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = init_openai_client()

    # ë²¡í„° DB ì´ˆê¸°í™”
    with st.spinner("ETF ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì¤‘..."):
        vectorstore = init_vector_db()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë©˜í†  í”¼ë“œë°±: ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê¸°ë¡)
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "last_sources" not in st.session_state:
        st.session_state.last_sources = []
    if "last_answer" not in st.session_state:
        st.session_state.last_answer = ""
    if "last_question" not in st.session_state:
        st.session_state.last_question = ""

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
    if not st.session_state.messages:
        st.markdown("### ğŸ’¡ ì´ëŸ° ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”:")
        col1, col2 = st.columns(2)

        example_questions = [
            "KODEX 200 ETFì— ëŒ€í•´ ì•Œë ¤ì¤˜",
            "ë¯¸êµ­ ì£¼ì‹ì— íˆ¬ìí•˜ëŠ” ETF ì¶”ì²œí•´ì¤˜",
            "2ì°¨ì „ì§€ ê´€ë ¨ ETFì˜ ìœ„í—˜ë„ëŠ”?",
            "ë°°ë‹¹ ìˆ˜ìµë¥ ì´ ë†’ì€ ETFëŠ”?"
        ]

        with col1:
            if st.button(example_questions[0], use_container_width=True):
                st.session_state.example_q = example_questions[0]
                st.rerun()
            if st.button(example_questions[2], use_container_width=True):
                st.session_state.example_q = example_questions[2]
                st.rerun()

        with col2:
            if st.button(example_questions[1], use_container_width=True):
                st.session_state.example_q = example_questions[1]
                st.rerun()
            if st.button(example_questions[3], use_container_width=True):
                st.session_state.example_q = example_questions[3]
                st.rerun()

    # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
    example_question = st.session_state.pop("example_q", None)

    # ì±„íŒ… ì…ë ¥
    user_input = st.chat_input("ETFì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”...")

    # ì…ë ¥ ì²˜ë¦¬ (ì§ì ‘ ì…ë ¥ ë˜ëŠ” ì˜ˆì‹œ ì§ˆë¬¸)
    question = example_question or user_input

    if question:
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘
        total_start_time = time.time()

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            # [3ì£¼ì°¨] ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
            question_type = classify_question_type(question)
            st.session_state.last_question_type = question_type

            # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ì‹œê°„ ì¸¡ì •)
            search_start_time = time.time()
            context, sources = retrieve_relevant_docs(vectorstore, question)
            search_time = time.time() - search_start_time

            st.session_state.last_sources = sources
            st.session_state.last_question = question

            # [3ì£¼ì°¨] ì§ˆë¬¸ ìœ í˜• í‘œì‹œ (ë””ë²„ê·¸ìš©)
            type_labels = {
                "simple": "ğŸ“ ë‹¨ìˆœ ì •ë³´",
                "compare": "âš–ï¸ ë¹„êµ ë¶„ì„",
                "recommend": "ğŸ’¡ ì¶”ì²œ",
                "risk": "âš ï¸ ìœ„í—˜ ë¶„ì„",
                "general": "ğŸ“š ì¼ë°˜ ì§ˆë¬¸"
            }
            st.caption(f"ì§ˆë¬¸ ìœ í˜•: {type_labels.get(question_type, question_type)}")

            # 2. LLM ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (ì‹œê°„ ì¸¡ì •)
            llm_start_time = time.time()
            response_stream = call_llm_streaming(
                client, context, question, st.session_state.messages, question_type
            )

            if response_stream:
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                answer_placeholder = st.empty()
                full_response = ""

                for chunk in response_stream:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        answer_placeholder.markdown(full_response + "â–Œ")

                llm_time = time.time() - llm_start_time
                total_time = time.time() - total_start_time

                answer_placeholder.markdown(full_response)
                st.session_state.last_answer = full_response

                # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response
                })

                # ì°¸ê³  ETF í‘œì‹œ
                if sources:
                    st.divider()
                    st.markdown("**ğŸ” ê²€ìƒ‰ëœ ETF ì •ë³´:**")
                    for src in sources:
                        st.write(f"- **{src['id']}** {src['name']} ({src['ticker']}) - ê´€ë ¨ë„: {src['relevance_score']:.0%}")

                # [3ì£¼ì°¨] ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
                st.caption(f"â±ï¸ ì‘ë‹µì‹œê°„: {total_time*1000:.0f}ms (ê²€ìƒ‰: {search_time*1000:.0f}ms, LLM: {llm_time*1000:.0f}ms)")

                # ë¡œê·¸ ì €ì¥ (3ì£¼ì°¨: ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨)
                log_interaction(
                    question=question,
                    answer=full_response,
                    sources=sources,
                    question_type=question_type,
                    search_time=search_time,
                    llm_time=llm_time,
                    total_time=total_time
                )

    # í”¼ë“œë°± ë²„íŠ¼ (ë©˜í†  í”¼ë“œë°±: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘)
    if st.session_state.last_answer:
        st.divider()
        col1, col2, col3 = st.columns([1, 1, 4])

        with col1:
            if st.button("ğŸ‘ ë„ì›€ë¨", key="feedback_positive"):
                log_feedback(
                    st.session_state.last_question,
                    st.session_state.last_answer,
                    "positive"
                )
                st.success("í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤!")

        with col2:
            if st.button("ğŸ‘ ë³„ë¡œ", key="feedback_negative"):
                log_feedback(
                    st.session_state.last_question,
                    st.session_state.last_answer,
                    "negative"
                )
                st.info("ê°œì„ ì— ì°¸ê³ í•˜ê² ìŠµë‹ˆë‹¤!")

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.messages:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.last_sources = []
            st.session_state.last_answer = ""
            st.session_state.last_question = ""
            st.rerun()

if __name__ == "__main__":
    main()
